{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "warnings.filterwarnings(\"ignore\", message=\"pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\")\n",
    "\n",
    "proj_dir = '/Users/nickbachelder/Desktop/Kaggle/Linemen'\n",
    "\n",
    "os.chdir( os.path.join(proj_dir, 'code/clean') )\n",
    "\n",
    "%run clean_objects.ipynb\n",
    "\n",
    "\n",
    "class RushDataset(Dataset):\n",
    "    def __init__(self, sequences, sequence_length):\n",
    "        self.sequences = sequences\n",
    "        self.sequence_length = sequence_length\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "        label = int(label)\n",
    "        labels = np.repeat(label, self.sequence_length)\n",
    "        if sequence.shape[0] > self.sequence_length:\n",
    "            sequence = sequence.iloc[0:self.sequence_length]\n",
    "        if sequence.shape[0] < self.sequence_length:\n",
    "            # padding = pd.DataFrame(0, index=np.arange(self.sequence_length - sequence.shape[0]), columns=sequence.columns) zero pad does not work\n",
    "            padding = pd.DataFrame(sequence.iloc[-1:].copy())\n",
    "            num_padded = self.sequence_length - sequence.shape[0]\n",
    "            padding_rep = pd.DataFrame(np.repeat(padding.values, num_padded, axis=0)) \n",
    "            padding_rep.columns = sequence.columns\n",
    "            sequence = pd.concat([sequence, padding_rep])\n",
    "\n",
    "        label_tensor = torch.Tensor(labels).long()\n",
    "        data_tensor = torch.Tensor(sequence.values)\n",
    "            \n",
    "        return data_tensor, label_tensor\n",
    "\n",
    "class SequenceModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_classes, n_hidden, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.ltsm = torch.nn.LSTM(input_size = n_features, hidden_size = n_hidden, num_layers = n_layers, batch_first = True)\n",
    "        self.classifier = torch.nn.Linear(n_hidden, n_classes)\n",
    "    def forward(self, x):\n",
    "        unfolded_hiddens, (_, _) = self.ltsm(x)\n",
    "        fc_output = self.classifier(unfolded_hiddens)\n",
    "        return fc_output\n",
    "    def get_layer_probabilities(self, x):\n",
    "        fc_output = self.forward(x)\n",
    "        fc_output_long = fc_output.view([x.size(0) * x.size(1), self.n_classes])\n",
    "        time_prob = torch.nn.functional.softmax(fc_output_long, dim = 1).detach().cpu().numpy().tolist()\n",
    "        time_prob_sack = [x[1] for x in time_prob]\n",
    "        return time_prob_sack\n",
    "\n",
    "\n",
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    outputs = []\n",
    "    labels = []\n",
    "    time_frame_losses = {}\n",
    "    time_frame_labels = {}\n",
    "    time_frame_fc_outputs = {}\n",
    "    i = 0\n",
    "    for X, y in data_loader:\n",
    "        i += 1\n",
    "        fc_output = model(X)\n",
    "        fc_output_long = fc_output.view([data_loader.dataset.sequence_length * X.size(0), model.n_classes])\n",
    "        y_long = y.view([data_loader.dataset.sequence_length * X.size(0)])\n",
    "        outputs.extend([x[0] for x in fc_output_long.detach().numpy().tolist()])\n",
    "        labels.extend(y_long.numpy())\n",
    "        loss = loss_function(fc_output_long, y_long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # get auc per 5 frames\n",
    "\n",
    "        time_frame_start = 0\n",
    "        if data_loader.dataset.sequence_length%5 != 0:\n",
    "            print('Pick a sequence length divisable by 5')\n",
    "            return None\n",
    "        for time_frames in range(int(data_loader.dataset.sequence_length / 5)):\n",
    "            time_frames += 1\n",
    "            this_time_frame_fc_output = fc_output[:, time_frame_start : time_frames*5, :].reshape([X.size(0) * 5, 2])\n",
    "            this_time_frame_ys = y[:, time_frame_start : time_frames*5].reshape([X.size(0) * 5])\n",
    "            loss_this_time_frame = loss_function(this_time_frame_fc_output, this_time_frame_ys)\n",
    "            if i == 1:\n",
    "                time_frame_losses.update({str(time_frames) : [loss_this_time_frame.item()]})\n",
    "                time_frame_labels.update({str(time_frames) : this_time_frame_ys.detach().cpu().numpy().tolist()})\n",
    "                time_frame_fc_outputs.update({str(time_frames) : this_time_frame_fc_output.detach().cpu().numpy().tolist()})\n",
    "            else:\n",
    "                time_frame_losses[str(time_frames)].extend([loss_this_time_frame.item()])\n",
    "                time_frame_labels[str(time_frames)].extend(this_time_frame_ys.detach().cpu().numpy().tolist())\n",
    "                time_frame_fc_outputs[str(time_frames)].extend(this_time_frame_fc_output.detach().cpu().numpy().tolist())\n",
    "            time_frame_start = time_frame_start + 5\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    tpr, fpr, thresholds = sklearn.metrics.roc_curve(y_true = labels, y_score = outputs, pos_label = 1)\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    print(f\"Overall Train loss: {avg_loss} , Overall Train AUC: {auc}\")\n",
    "\n",
    "    for time_period in time_frame_losses.keys():\n",
    "        losses = time_frame_losses[time_period]\n",
    "        labels = time_frame_labels[time_period]\n",
    "        outputs_fc = [x[0] for x in time_frame_fc_outputs[time_period]]\n",
    "        \n",
    "        avg_loss = sum(losses) / num_batches\n",
    "        tpr, fpr, thresholds = sklearn.metrics.roc_curve(y_true = labels, y_score = outputs_fc, pos_label = 1)\n",
    "        auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        print(f\"Train loss for period {time_period}: {avg_loss} , Train AUC for period {time_period}: {auc}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    i = 0\n",
    "    time_frame_losses = {}\n",
    "    time_frame_labels = {}\n",
    "    time_frame_fc_outputs = {}\n",
    "    with torch.no_grad():\n",
    "        outputs = []\n",
    "        labels = []\n",
    "        for X, y in data_loader:\n",
    "            i += 1\n",
    "            fc_output = model(X)\n",
    "            fc_output_long = fc_output.view([data_loader.dataset.sequence_length * X.size(0), model.n_classes])\n",
    "            y_long = y.view([data_loader.dataset.sequence_length * X.size(0)])\n",
    "            outputs.extend([x[0] for x in fc_output_long.detach().numpy().tolist()])\n",
    "            labels.extend(y_long.numpy())\n",
    "            total_loss += loss_function(fc_output_long, y_long).item()\n",
    "\n",
    "            time_frame_start = 0\n",
    "            if data_loader.dataset.sequence_length%5 != 0:\n",
    "                print('Pick a sequence length divisable by 5')\n",
    "                return None\n",
    "            for time_frames in range(int(data_loader.dataset.sequence_length / 5)):\n",
    "                time_frames += 1\n",
    "                this_time_frame_fc_output = fc_output[:, time_frame_start : time_frames*5, :].reshape([X.size(0) * 5, 2])\n",
    "                this_time_frame_ys = y[:, time_frame_start : time_frames*5].reshape([X.size(0) * 5])\n",
    "                loss_this_time_frame = loss_function(this_time_frame_fc_output, this_time_frame_ys)\n",
    "                if i == 1:\n",
    "                    time_frame_losses.update({str(time_frames) : [loss_this_time_frame.item()]})\n",
    "                    time_frame_labels.update({str(time_frames) : this_time_frame_ys.detach().cpu().numpy().tolist()})\n",
    "                    time_frame_fc_outputs.update({str(time_frames) : this_time_frame_fc_output.detach().cpu().numpy().tolist()})\n",
    "                else:\n",
    "                    time_frame_losses[str(time_frames)].extend([loss_this_time_frame.item()])\n",
    "                    time_frame_labels[str(time_frames)].extend(this_time_frame_ys.detach().cpu().numpy().tolist())\n",
    "                    time_frame_fc_outputs[str(time_frames)].extend(this_time_frame_fc_output.detach().cpu().numpy().tolist())\n",
    "                time_frame_start = time_frame_start + 5\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    tpr, fpr, thresholds = sklearn.metrics.roc_curve(y_true = labels, y_score = outputs, pos_label = 1)\n",
    "    auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    print(f\"Overall test loss: {avg_loss} , Overall test AUC: {auc}\")\n",
    "\n",
    "    for time_period in time_frame_losses.keys():\n",
    "        losses = time_frame_losses[time_period]\n",
    "        labels = time_frame_labels[time_period]\n",
    "        outputs_fc = [x[0] for x in time_frame_fc_outputs[time_period]]\n",
    "        \n",
    "        avg_loss = sum(losses) / num_batches\n",
    "        tpr, fpr, thresholds = sklearn.metrics.roc_curve(y_true = labels, y_score = outputs_fc, pos_label = 1)\n",
    "        auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        print(f\"Test loss for period {time_period}: {avg_loss} , Test AUC for period {time_period}: {auc}\")\n",
    "\n",
    "def train_rush_lstm(train_loader, test_loader, model, loss_function, optimizer, num_epochs = 10):\n",
    "    for ix_epoch in range(num_epochs):\n",
    "        print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "        model = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "        test_model(test_loader, model, loss_function)\n",
    "        print()\n",
    "    return(model)\n",
    "\n",
    "def predict_play(master_track, play_id, model, normalize = True, replace_player = None):\n",
    "    week = master_track.search_track_weeks(variables = [\"playId\"], variable_values = [play_id]).reset_index(drop = True).week.tolist()[0]\n",
    "    play_dat_label = master_track.get_rush_sequences_labels(week = week + 1, normalize = normalize, play_id = play_id, replace_player = replace_player)\n",
    "    play_dataset = RushDataset(sequences = play_dat_label, sequence_length=50)\n",
    "    play_loader = DataLoader(play_dataset, batch_size = 1, shuffle = False)\n",
    "\n",
    "    outputs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in play_loader:\n",
    "            y_star = model.get_layer_probabilities(X)\n",
    "            outputs.extend(y_star)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( os.path.join(proj_dir, 'code/modeling') )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b5140b98f9aa636ad904647e184ddf94a8c49b25e448223e4f659e3845abf7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
