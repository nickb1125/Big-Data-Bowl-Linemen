{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from functools import reduce\n",
    "import sklearn\n",
    "\n",
    "class master_track:\n",
    "    def __init__(self, track_paths, play_info_path, play_details_path, players_path):\n",
    "\n",
    "        # sort tracking files into proper order\n",
    "        file_dict = {file : int(''.join(filter(lambda i: i.isdigit(), file))) for file in track_paths}\n",
    "        file_dict_sorted = dict(sorted(file_dict.items(), reverse = False, key=lambda item: item[1]))\n",
    "        track_paths = file_dict_sorted.keys()\n",
    "\n",
    "\n",
    "        self.d_line_pos = [\"NT\", \"DT\", \"MLB\", \"ILB\", \"LB\",  \"OLB\"]\n",
    "        self.o_line_pos = [\"T\", \"C\", \"G\"]\n",
    "        self.qb_pos = [\"QB\"]\n",
    "\n",
    "        player_df = pd.read_csv(players_path)\n",
    "        self.player_df = player_df\n",
    "        self.o_linemen_player_ids = self.player_df.loc[self.player_df['officialPosition'].isin(self.o_line_pos)].nflId.unique()\n",
    "        self.d_linemen_player_ids = self.player_df.loc[self.player_df['officialPosition'].isin(self.d_line_pos)].nflId.unique()\n",
    "        self.all_linemen = np.append(self.o_linemen_player_ids, self.d_linemen_player_ids)\n",
    "\n",
    "        self.play_info_df = pd.read_csv(play_info_path)\n",
    "        self.play_info_df['playId'] = (self.play_info_df['gameId'].apply(str) + self.play_info_df['playId'].apply(str)).apply(int)\n",
    "        self.play_details_df = pd.read_csv(play_details_path)\n",
    "        self.play_details_df['playId'] = (self.play_details_df['gameId'].apply(str) + self.play_details_df['playId'].apply(str)).apply(int)\n",
    "        self.play_details_df['disrupt_individual'] = (self.play_details_df.pff_hit + self.play_details_df.pff_hurry + self.play_details_df.pff_sack) > 0\n",
    "        team_dets = self.play_details_df.groupby('playId').agg({'disrupt_individual' : [sum]})\n",
    "        team_dets.columns = [\"_\".join(x) for x in np.array(team_dets.columns).ravel()]\n",
    "        team_dets = team_dets.reset_index()\n",
    "        team_dets['disrupt_team'] = team_dets.disrupt_individual_sum > 0\n",
    "        team_dets = team_dets.loc[:,['playId', 'disrupt_team']].drop_duplicates()\n",
    "        self.play_details_df = self.play_details_df.merge(team_dets, on = 'playId', how = 'left').copy()\n",
    "        self.max_time_after_snap = 7\n",
    "        \n",
    "        self.track_dfs = {}\n",
    "        week_num = 1\n",
    "        for week_path in tqdm.tqdm(track_paths):\n",
    "            week = pd.read_csv(week_path)\n",
    "            week['playId'] = (week['gameId'].apply(str) + week['playId'].apply(str)).apply(int)\n",
    "            week['week'] = week_num\n",
    "            snap_frames_df = week.loc[week.event == 'ball_snap', ['playId', 'frameId']].drop_duplicates().reset_index(drop  = True).rename(columns = {'frameId' : 'snap_frame'})\n",
    "            week = week.merge(snap_frames_df, on = 'playId', how = 'left')\n",
    "            week['time_after_snap'] = (week.frameId - week.snap_frame) * 0.1\n",
    "            no_snap = week.loc[week.time_after_snap.isnull()].drop_duplicates().playId.tolist()\n",
    "            week = week.loc[~(week.playId.isin(no_snap))]\n",
    "            no_before_snap = week.loc[week.groupby('playId').time_after_snap.idxmin().tolist()].query('time_after_snap >= 0').drop_duplicates().playId.tolist()   # must have data from before snap\n",
    "            week = week.loc[~(week.playId.isin(no_before_snap))]\n",
    "\n",
    "            # remove ball (it should be with qb the whole time we care about)\n",
    "\n",
    "            week = week.loc[~(np.isnan(week.nflId))]\n",
    "\n",
    "            # filter all plays to before pass\n",
    "\n",
    "            week = week[week.groupby(['playId', 'nflId'])['event'].apply(lambda x: x.shift().eq('autoevent_passforward').cumsum().eq(0))]\n",
    "            week = week[week.groupby(['playId', 'nflId'])['event'].apply(lambda x: x.shift().eq('pass_forward').cumsum().eq(0))]\n",
    "\n",
    "\n",
    "            self.track_dfs.update( {''.join(filter(lambda i: i.isdigit(), week_path)) : week} )\n",
    "            week_num += 1\n",
    "\n",
    "        self.individual_play_avgs = {key : None for key in self.track_dfs.keys()}\n",
    "        self.training_data_individual = {key : None for key in self.track_dfs.keys()}\n",
    "        self.training_data_team = {key : None for key in self.track_dfs.keys()}\n",
    "\n",
    "\n",
    "    def search_track_weeks(self, variables, variable_values):\n",
    "        needed = pd.DataFrame()\n",
    "        for week in range (len(self.track_dfs)):\n",
    "            week = str(week + 1)\n",
    "            curr_week = self.track_dfs.get(week)\n",
    "            if len(variables) == 2:\n",
    "                needed_info = curr_week.loc[(curr_week[variables[0]] == variable_values[0]) & (curr_week[variables[1]] == variable_values[1])]\n",
    "            else:\n",
    "                needed_info = curr_week.loc[(curr_week[variables[0]] == variable_values[0])]\n",
    "            needed = pd.concat([needed, needed_info])\n",
    "        return(needed.reset_index(drop = True))\n",
    "\n",
    "    def get_qb_track_on_play(self, play_id):\n",
    "        qb_play = self.play_details_df\n",
    "        qb_id = qb_play.loc[(qb_play.playId == play_id) & (qb_play.pff_positionLinedUp == 'QB')].reset_index(drop = 0).nflId[0]\n",
    "\n",
    "        qb_track = self.search_track_weeks(variables = [\"nflId\", \"playId\"], variable_values = [qb_id, play_id]).reset_index(drop = True)\n",
    "        return(qb_track)\n",
    "\n",
    "    def get_defender_and_qb_info_on_play(self, play_id):\n",
    "        # get qb and def data\n",
    "        # get def track\n",
    "        def_match = self.play_details_df.loc[(self.play_details_df.playId == play_id) & (self.play_details_df.pff_nflIdBlockedPlayer.notna()), ['playId', 'nflId', 'pff_nflIdBlockedPlayer']]\n",
    "        defender_track = []\n",
    "        for defender in def_match.nflId:\n",
    "            this_def = self.search_track_weeks(variables = [\"playId\", \"nflId\"], variable_values = [play_id, defender])\n",
    "            defender_track.append(this_def)\n",
    "        try:\n",
    "            defender_track = pd.concat(defender_track).merge(def_match, on = ['playId', 'nflId'], how = 'left').loc[:,['nflId', 'playId', 'time_after_snap', 'pff_nflIdBlockedPlayer', 'x', 'y']].rename(columns = {'pff_nflIdBlockedPlayer' : 'nflId', 'nflId' : 'blockerId', 'x' : 'x_block', 'y' : 'y_block'})\n",
    "\n",
    "        except ValueError:\n",
    "            # case were there are NO blockers or NO rushers (QB can't be too happy about that one): remove this play, not useful to well assess rushers\n",
    "            return None\n",
    "\n",
    "        # get qb track\n",
    "        qb_track = self.get_qb_track_on_play(play_id).loc[:, ['playId', 'time_after_snap', 'x', 'y', 's', 'a']].rename(columns = {'x' : 'x_qb', 'y' : 'y_qb', 's' : 's_qb', 'a' : 'a_qb'})\n",
    "        defender_qb_track = defender_track.merge(qb_track, on = ['playId', 'time_after_snap'], how = 'left')\n",
    "        defender_qb_track['blocker_distance_from_qb'] = np.sqrt( (defender_qb_track.x_qb - defender_qb_track.x_block)**2 + (defender_qb_track.y_qb - defender_qb_track.y_block)**2 )\n",
    "\n",
    "        dist_at_snap = defender_qb_track.loc[defender_qb_track.time_after_snap == 0, ['blockerId', 'blocker_distance_from_qb']].rename(columns = {'blocker_distance_from_qb' : 'distance_from_qb_at_snap'})\n",
    "        defender_qb_track = defender_qb_track.merge(dist_at_snap, on = 'blockerId', how = 'left')\n",
    "        defender_qb_track['blocker_distance_toward_qb_gained'] = defender_qb_track['distance_from_qb_at_snap'] - defender_qb_track['blocker_distance_from_qb']\n",
    "        def_qb_dat = defender_qb_track.drop(['distance_from_qb_at_snap'], axis = 1)\n",
    "\n",
    "        # get defender track wide\n",
    "\n",
    "        defender_track_wide = []\n",
    "        for column in ['blockerId', 'x_block', 'y_block', 'blocker_distance_from_qb', 'blocker_distance_toward_qb_gained']:\n",
    "            this_col_widen = def_qb_dat.groupby(['playId', 'time_after_snap', 'nflId'])[column].apply(lambda s: pd.Series(s.values, index=[f'{column}%s' % i for i in range(s.shape[0])])).unstack(-1).reset_index()\n",
    "            defender_track_wide.append(this_col_widen)\n",
    "        defender_track_wide = reduce(lambda x, y: pd.merge(x, y, on = ['playId', 'time_after_snap', 'nflId']), defender_track_wide).sort_values(['nflId', 'time_after_snap'])\n",
    "        def_qb_dat = def_qb_dat.drop(['blockerId', 'x_block', 'y_block', 'blocker_distance_from_qb', 'blocker_distance_toward_qb_gained'], axis = 1).merge(defender_track_wide, on = ['playId', 'time_after_snap', 'nflId'], how = 'left')\n",
    "\n",
    "        return(def_qb_dat)\n",
    "\n",
    "    def get_play(self, play_id):\n",
    "        def_qb_dat = self.get_defender_and_qb_info_on_play(play_id)\n",
    "        if def_qb_dat is None:\n",
    "            return None\n",
    "        # separate qb and def data \n",
    "        qb_dat = def_qb_dat.loc[:,['time_after_snap', 'x_qb', 'y_qb', 's_qb', 'a_qb']].drop_duplicates()\n",
    "        def_dat = def_qb_dat.drop(['x_qb', 'y_qb', 's_qb', 'a_qb'], axis = 1)\n",
    "        #get pass rusher\n",
    "        rush_ids = self.play_details_df.loc[(self.play_details_df.pff_role == \"Pass Rush\") & (self.play_details_df.playId == play_id)].nflId.tolist()\n",
    "        play = self.search_track_weeks(variables = [\"playId\"], variable_values = [play_id])\n",
    "        play = play.loc[(play.nflId.isin(rush_ids))]\n",
    "        # create rush qb relationship data\n",
    "        play = play.merge(qb_dat, on = 'time_after_snap', how ='left')\n",
    "        play['rusher_distance_from_qb'] = np.sqrt( (play.x_qb - play.x)**2 + (play.y_qb - play.y)**2 )\n",
    "        dist_at_snap = play.loc[play.frameId == play.snap_frame, ['nflId', 'rusher_distance_from_qb']].rename(columns = {'rusher_distance_from_qb' : 'distance_from_qb_at_snap'})\n",
    "        play = play.merge(dist_at_snap, on = 'nflId', how = 'left')\n",
    "        play['rusher_distance_toward_qb_gained'] = play.distance_from_qb_at_snap - play.rusher_distance_from_qb\n",
    "        dis_gained_this_play_to_qb, change_in_velocity_this_play = [0], [0]\n",
    "        dis_gained_this_play_to_qb.extend(np.diff(play.rusher_distance_from_qb) * - 1)\n",
    "        play['rusher_velocity_towards_qb'] = np.array(dis_gained_this_play_to_qb) / 0.1\n",
    "        change_in_velocity_this_play.extend(np.diff(play.rusher_velocity_towards_qb))\n",
    "        play['rusher_acceleration_towards_qb'] = np.array(change_in_velocity_this_play) / 0.1\n",
    "        #get rusher blocker data ralations\n",
    "        play_w_dup_blockers = play.merge(def_dat, on = ['playId', 'time_after_snap', 'nflId'], how = 'left')\n",
    "        play_w_dup_blockers.loc[play_w_dup_blockers.blockerId0.notna()]\n",
    "        all_blockers_accounted_for = False\n",
    "        id = 0\n",
    "        while all_blockers_accounted_for == False:\n",
    "            try:\n",
    "                play_w_dup_blockers['blocker_in_front' + str(id)] = (play_w_dup_blockers['blocker_distance_from_qb' + str(id)] - play_w_dup_blockers['rusher_distance_from_qb']) < 0\n",
    "                play_w_dup_blockers['blocker_distance_from_rusher' + str(id)] = np.sqrt( (play_w_dup_blockers['x_block' + str(id)] - play_w_dup_blockers['x'])**2 + (play_w_dup_blockers['y_block' + str(id)] - play_w_dup_blockers['y'])**2 )\n",
    "                id += 1\n",
    "            except:\n",
    "                all_blockers_accounted_for = True\n",
    "        play_w_dup_blockers['blockers_left'] = sum([play_w_dup_blockers['blocker_in_front' + str(this_id)] for this_id in range(id)])\n",
    "        play_w_dup_blockers['number_blockers_on_play'] = sum([play_w_dup_blockers['blockerId' + str(this_id)].notna() for this_id in range(id)])\n",
    "        [play_w_dup_blockers['blocker_distance_from_rusher' + str(this_id)] for this_id in range(id)]\n",
    "        play_w_dup_blockers['distance_of_closest_blocker_in_front'] = np.where(play_w_dup_blockers['blockers_left'] > 0, play_w_dup_blockers.loc[:,['blocker_distance_from_rusher' + str(this_id) for this_id in range(id)]].min(axis=1), 0)\n",
    "        play = play_w_dup_blockers.loc[play_w_dup_blockers.time_after_snap >= 0,[\n",
    "            'gameId', 'playId', 'nflId', 'time_after_snap', 'team', 'week',\n",
    "            'x', 'y', 'rusher_velocity_towards_qb', 'rusher_acceleration_towards_qb',\n",
    "            'x_qb', 'y_qb', 's_qb', 'a_qb',\n",
    "            'rusher_distance_from_qb', 'rusher_distance_toward_qb_gained',  'distance_of_closest_blocker_in_front', 'blockers_left', 'number_blockers_on_play']]\n",
    "        return(play)\n",
    "\n",
    "    def load_training_data(self, week):\n",
    "        if week < 2:\n",
    "            print(\"Must check for week after week 1 to have data\")\n",
    "            return(None)\n",
    "        needed_weeks = list(range(1, week))\n",
    "        for each_week in needed_weeks:\n",
    "            print(f'Getting week {each_week} training data')\n",
    "            if (str(each_week) in self.track_dfs.keys()) and not (self.training_data_team.get(str(each_week)) is None) :\n",
    "                next\n",
    "            else:\n",
    "                all_individual_df = []\n",
    "                all_team_df = []\n",
    "                plays_this_week = np.unique(self.track_dfs.get(str(each_week)).playId).tolist()\n",
    "                for play_id in tqdm.tqdm(plays_this_week):\n",
    "                    play_individual_df = self.get_play(play_id = play_id)\n",
    "                    if play_individual_df is None:\n",
    "                        # remove plays with no blockers as you find them\n",
    "                        self.track_dfs[str(each_week)] = self.track_dfs[\"1\"].query('playId != @play_id')\n",
    "                        self.play_details_df = self.play_details_df.query('playId != @play_id')\n",
    "                        self.play_info_df = self.play_info_df.query('playId != @play_id')\n",
    "                        continue\n",
    "                    all_individual_df.append(play_individual_df)\n",
    "                all_individual_df = pd.concat(all_individual_df)\n",
    "                all_team_df = all_individual_df.groupby(['playId', 'time_after_snap'], as_index=False).agg({\n",
    "                    'nflId' : pd.Series.nunique,\n",
    "                    's_qb' : [min],\n",
    "                    'a_qb' : [min],\n",
    "                    'blockers_left' : [min, max, sum],\n",
    "                    'rusher_velocity_towards_qb' : [min, max, np.average],\n",
    "                    'rusher_acceleration_towards_qb' : [min, max, np.average],\n",
    "                    \"rusher_distance_from_qb\": [min, max, np.average],\n",
    "                    \"rusher_distance_toward_qb_gained\": [min, max, np.average],\n",
    "                    \"distance_of_closest_blocker_in_front\": [min, max, np.average]})\n",
    "                all_team_df.columns = [\"_\".join(x) for x in np.array(all_team_df.columns).ravel()]\n",
    "                all_team_df = all_team_df.rename(columns = {'playId_' : 'playId', 'time_after_snap_' : 'time_after_snap'}).rename(columns = {'nflId_nunique' : 'n_rushers', 's_qb_min' : 's_qb', 'a_qb_min' : 'a_qb'})\n",
    "                all_team_df['week'] = each_week\n",
    "\n",
    "                results_data = self.play_details_df.fillna(0)\n",
    "                results_data_ind = results_data.loc[:, ['nflId', 'playId', 'pff_positionLinedUp', 'disrupt_individual']]\n",
    "                results_data_ind.pff_positionLinedUp = np.select(\n",
    "                            [\n",
    "                                (['E' in position for position in results_data_ind.pff_positionLinedUp]), \n",
    "                                (['B' in position for position in results_data_ind.pff_positionLinedUp]),\n",
    "                                (['T' in position for position in results_data_ind.pff_positionLinedUp])\n",
    "\n",
    "                            ], \n",
    "                            [\n",
    "                                'End', \n",
    "                                'Back',\n",
    "                                'Tackle'\n",
    "\n",
    "                            ], \n",
    "                            default='Non-Lineman'\n",
    "                        )\n",
    "                results_data_team = results_data.loc[:, ['playId', 'disrupt_team']].drop_duplicates()\n",
    "                training_df_individual = all_individual_df.merge(results_data_ind, on = ['nflId', 'playId'], how = 'left')\n",
    "                training_df_team = all_team_df.merge(results_data_team, on = ['playId'], how = 'left')\n",
    "                \n",
    "                self.training_data_individual[str(each_week)] = training_df_individual\n",
    "                self.training_data_team[str(each_week)] = training_df_team\n",
    "        print('Done')\n",
    "\n",
    "\n",
    "    def get_averages_up_to_week(self, week):\n",
    "        if week < 2:\n",
    "            print(\"Must check for week after week 1 to have data\")\n",
    "            return(None)\n",
    "        needed_weeks = list(range(1, week))\n",
    "        progressive_training_indivudual = []\n",
    "        for each_week in needed_weeks:\n",
    "            print(f'Getting week {each_week} average metrics by position and blocker number')\n",
    "            if (str(each_week) in self.track_dfs.keys()) and not (self.training_data_individual.get(str(each_week)) is None) :\n",
    "                next\n",
    "            try:\n",
    "                this_week_train_dat = self.training_data_individual.get(str(each_week))\n",
    "            except:\n",
    "                print(f'Training data has not been loaded for week {str(each_week)}')\n",
    "                return(None)\n",
    "            progressive_training_indivudual.append(this_week_train_dat)\n",
    "            all_before_this_week = pd.concat(progressive_training_indivudual)  \n",
    "            player_averages = all_before_this_week.groupby(['time_after_snap', 'number_blockers_on_play', 'pff_positionLinedUp']).agg({\n",
    "                                                            'nflId' : pd.Series.nunique,\n",
    "                                                            'blockers_left' : [np.median],\n",
    "                                                            'rusher_velocity_towards_qb' : [np.average],\n",
    "                                                            'rusher_acceleration_towards_qb' : [np.average],\n",
    "                                                            \"rusher_distance_from_qb\": [np.average],\n",
    "                                                            \"rusher_distance_toward_qb_gained\": [np.average],\n",
    "                                                            \"distance_of_closest_blocker_in_front\": [np.average]\n",
    "                                                            })\n",
    "            player_averages.columns = [\"_\".join(x) for x in np.array(player_averages.columns).ravel()]\n",
    "            player_averages = player_averages.rename(columns = {'time_after_snap_' : 'time_after_snap'}).rename(columns = {'nflId_nunique' : 'n_rushers'}).reset_index()\n",
    "            self.individual_play_avgs[str(each_week)] = player_averages\n",
    "        print('Done')\n",
    "\n",
    "    def get_rush_sequences_labels(self, week, week_id = 'all', play_id = 'all', normalize = True, replace_player = None, messages = False):\n",
    "        if (play_id == 'all') & (replace_player != None):\n",
    "            print('Can only replace player for outputs of one play')\n",
    "            return None\n",
    "        if ( (week_id != 'all') & (play_id != 'all') ):\n",
    "            print('Filter on EITHER week or playId but not both.')\n",
    "            return None\n",
    "        if (replace_player != None):\n",
    "            play_week = self.search_track_weeks(variables = [\"playId\"], variable_values = [play_id]).reset_index(drop = True).week.tolist()[0]\n",
    "        else:\n",
    "            play_week = None\n",
    "        needed_weeks = list(range(1, week))\n",
    "        progressive_training_team = []\n",
    "        for each_week in needed_weeks:\n",
    "            if (normalize == True) & (messages == True):\n",
    "                print(f'Getting week {each_week} normalized training data')\n",
    "            if (normalize == False) & (messages == True):\n",
    "                print(f'Getting week {each_week} (unnormalized) training data')\n",
    "            try:\n",
    "                if (replace_player == None) or (each_week != play_week):\n",
    "                    this_week_train_dat = self.training_data_team.get(str(each_week))\n",
    "                else:\n",
    "                    this_week_train_dat = self.training_data_team.get(str(each_week))\n",
    "                    replaced_player_play = self.replace_player_with_average(play_id, replace_player)\n",
    "                    this_week_train_dat = this_week_train_dat.loc[this_week_train_dat.playId != play_id]\n",
    "                    this_week_train_dat = pd.concat([this_week_train_dat, replaced_player_play])\n",
    "            except:\n",
    "                print(f'Training data has not been loaded for week {str(each_week)}')\n",
    "            progressive_training_team.append(this_week_train_dat)\n",
    "\n",
    "        all_training = pd.concat(progressive_training_team)\n",
    "\n",
    "        if normalize == True:\n",
    "                scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "                scale_cols = all_training.drop(['time_after_snap', 'playId', 'week', 'disrupt_team'], axis = 1)\n",
    "                non_scale_cols = all_training.loc[:,['time_after_snap', 'playId', 'week', 'disrupt_team']]\n",
    "                columns = scale_cols.columns\n",
    "                scale_cols = pd.DataFrame(scaler.fit_transform(scale_cols))\n",
    "                scale_cols.columns = columns\n",
    "                all_training = pd.concat([non_scale_cols.reset_index(drop = 1), scale_cols.reset_index(drop = 1)], axis = 1)\n",
    "\n",
    "        if week_id != 'all':\n",
    "            all_training = all_training.loc[all_training.week == week_id]\n",
    "        if play_id != 'all':\n",
    "            all_training = all_training.loc[all_training.playId == play_id]\n",
    "\n",
    "        sequences = []\n",
    "        for playId, group in all_training.groupby(\"playId\"):\n",
    "            label = group.iloc[0].disrupt_team\n",
    "            sequence_features = group.drop(['time_after_snap', 'playId', 'week', 'disrupt_team'], axis = 1)\n",
    "            sequences.append((sequence_features, label))\n",
    "        return(sequences)\n",
    "\n",
    "\n",
    "    def replace_player_with_average(self, play_id, player_id): \n",
    "\n",
    "        play_week = self.search_track_weeks(variables = [\"playId\"], variable_values = [play_id]).reset_index(drop = True).week.tolist()[0]\n",
    "        all_week = self.training_data_individual.get(str(play_week))\n",
    "        play_dat_individual = all_week.loc[(all_week.playId == play_id)]\n",
    "        lined_up_pos = play_dat_individual.loc[(play_dat_individual.nflId == player_id)].pff_positionLinedUp.tolist()[0]\n",
    "        num_blockers = play_dat_individual.loc[(play_dat_individual.nflId == player_id)].number_blockers_on_play.tolist()[0]\n",
    "        max_time_after_snap = max(play_dat_individual.loc[(play_dat_individual.nflId == player_id)].time_after_snap.tolist())\n",
    "        current_player = play_dat_individual.loc[(play_dat_individual.nflId == player_id)].copy()\n",
    "        current_player_keep = current_player.loc[:,['gameId', 'playId', 'nflId', 'team', 'week', 'x', \n",
    "                                                    'y', 'x_qb', 'y_qb', 's_qb', 'a_qb', 'disrupt_individual']].reset_index(drop = 1)\n",
    "\n",
    "\n",
    "        all_averages = self.individual_play_avgs.get(str(play_week))\n",
    "        condition_average = all_averages.loc[(all_averages.pff_positionLinedUp == lined_up_pos) & \n",
    "                                                (all_averages.number_blockers_on_play == num_blockers) &\n",
    "                                                (all_averages.time_after_snap <= max_time_after_snap)].reset_index(drop = 1).rename({'blockers_left_median' : 'blockers_left', \n",
    "                                                                    'rusher_velocity_towards_qb_average' : 'rusher_velocity_towards_qb',\n",
    "                                                                    'rusher_acceleration_towards_qb_average' : 'rusher_acceleration_towards_qb', \n",
    "                                                                    'rusher_distance_from_qb_average' : 'rusher_distance_from_qb', \n",
    "                                                                    'rusher_distance_toward_qb_gained_average' : 'rusher_distance_toward_qb_gained',\n",
    "                                                                    'distance_of_closest_blocker_in_front_average' : 'distance_of_closest_blocker_in_front'}, axis = 1)\n",
    "\n",
    "        \n",
    "        replace_averages = pd.concat([condition_average, current_player_keep], axis = 1).reset_index(drop = 1)\n",
    "        removed_player = play_dat_individual.loc[~(play_dat_individual.nflId == player_id)].reset_index(drop = 1)\n",
    "        replaced = pd.concat([replace_averages, removed_player])\n",
    "        replaced_team = replaced.groupby(['playId', 'time_after_snap'], as_index=False).agg({\n",
    "                                    'nflId' : pd.Series.nunique,\n",
    "                                    's_qb' : [min],\n",
    "                                    'a_qb' : [min],\n",
    "                                    'blockers_left' : [min, max, sum],\n",
    "                                    'rusher_velocity_towards_qb' : [min, max, np.average],\n",
    "                                    'rusher_acceleration_towards_qb' : [min, max, np.average],\n",
    "                                    \"rusher_distance_from_qb\": [min, max, np.average],\n",
    "                                    \"rusher_distance_toward_qb_gained\": [min, max, np.average],\n",
    "                                    \"distance_of_closest_blocker_in_front\": [min, max, np.average],\n",
    "                                    \"disrupt_individual\" : [sum],\n",
    "                                    \"week\" : [min]})\n",
    "        replaced_team.columns = [\"_\".join(x) for x in np.array(replaced_team.columns).ravel()]\n",
    "        replaced_team['disrupt_individual_sum'] = replaced_team['disrupt_individual_sum'] > 1\n",
    "        replaced_team = replaced_team.rename(columns = {'playId_' : 'playId', 'time_after_snap_' : 'time_after_snap'}).rename(columns = {'nflId_nunique' : 'n_rushers', \n",
    "                                                                                                                                        's_qb_min' : 's_qb', 'a_qb_min' : 'a_qb',\n",
    "                                                                                                                                        'disrupt_individual_sum' : 'disrupt_team',\n",
    "                                                                                                                                        'week_min' : 'week'})\n",
    "        return(replaced_team)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b5140b98f9aa636ad904647e184ddf94a8c49b25e448223e4f659e3845abf7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
